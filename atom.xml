<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Welcome to monkey-H's blog]]></title>
  <link href="http://monkey-h.github.io/atom.xml" rel="self"/>
  <link href="http://monkey-h.github.io/"/>
  <updated>2015-05-18T17:25:24+08:00</updated>
  <id>http://monkey-h.github.io/</id>
  <author>
    <name><![CDATA[monkey-H]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[My_paas_2]]></title>
    <link href="http://monkey-h.github.io/blog/my-paas-2/"/>
    <updated>2015-05-18T16:20:46+08:00</updated>
    <id>http://monkey-h.github.io/blog/my-paas-2</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>在理解了dokku，dokku-alt的基础上，我们设计自己的paas平台。我们的终极目标是在一个集群环境中设计一个paas平台，dokku只是单机环境下，为了我们的终极目标，我们最终选择的paas的底层平台是coreos集群环境。这几篇blog只是我们不断进行尝试的日志，并不是一个完整的教程，等我们最终搭建好了，可能会写一个完整的教程，但那都是后话。</p>

<!--more-->


<h3>客户端</h3>

<p>不着急，我们一步一步来。我们先来大体理一下思路，客户端git push，然后，服务器端接受到代码，然后部署，然后返回部署是否成功，ip地址和端口号是多少等，在运行的阶段，可能还会有健康检查，重新部署之类的东西。好了，大体思路有了，我们一点一点来实现。</p>

<p>首先来个简单的。git push的时候，服务器端调用服务器上的一个脚本。这里用到的知识就是我们之前说过的ssh forced command，可以看看之前写的blog，<a href="http://monkey-h.github.io/blog/dokkudao-di-gan-liao-shi-yao/">dokku源码解读1</a>.
git我们之前也介绍过了，git就是一个版本控制工具，而具备远程存储能力的git，也只不过是把本地的git repository移到远程服务器而已。而且我们知道，每次git push的时候，都会执行<code>ssh git@git.com git-receive-pack 'mygit.git'</code>，实际上也是执行了ssh命令。好了，第一步，我们就实现在客户端git push的时候，远程服务器通过本地的脚本，执行echo hello就可以了。</p>

<p>客户端不需要任何修改，在服务器端，修改对应客户端的rsa key。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh core@ip //我们之前已经装好了coreos集群，用户名就是core。
</span><span class='line'>vim ~/.ssh/authorized_keys //寻找自己的rsa key的位置。
</span><span class='line'>command="/home/core/script $SSH_ORIGINAL_COMMAND" ssh-rsa xxxxxx //在前面添加自己的ssh forced command，需要注意的是后面的那个参数，那个参数是系统自动填写的参数，假如客户端执行git push的时候，应该就是git-receive-pack 'mygit.git'。保存退出。
</span><span class='line'>cd /home/core
</span><span class='line'>touch script //我们在rsa key里加的command说使用了script脚本，当然要有这个脚本。
</span><span class='line'>vim script //编辑这个脚本，在这里面写下下面这两行命令。
</span><span class='line'>set -x   //第一行的意思是debug模式，这样我们才可以看到这个脚本执行到哪里了，有没有成功。
</span><span class='line'>echo hello</span></code></pre></td></tr></table></div></figure>


<p>好了，可以了，我们尝试一下。在客户端</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir hello //建立一个git文件夹，并初始化
</span><span class='line'>cd hello
</span><span class='line'>git init
</span><span class='line'>git remote add mypaas core@ip //添加远程仓库
</span><span class='line'>touch hello
</span><span class='line'>git commit -am "hello" //当仓库为空的时候，是不能push的时候。
</span><span class='line'>git push mypaas master //push</span></code></pre></td></tr></table></div></figure>


<p>这个时候，应该可以看到输出了hello。</p>

<p>attention：
需要注意的是，如果我们修改了rsa key前面的command，那么我们ssh进去服务器的时候，会执行command，而不会进去了，一定要注意这种情况，有可能导致你永远进不去系统。解决办法是你在coreos系统中重新建立一个用户，修改这个用户的rsa key前的command，而保存一个始终可以ssh进去的用户。但是我不知道coreos怎么给新用户赋予可以sudo权限，没有找到visudo，或者sudiors，等我知道了就在这里补充一下。所以我现在就保持有一个ssh到coreos的终端，或者每次下班了之后，就把rsa key中的command去除，下次尝试的时候再加进去。</p>

<h3>服务器</h3>

<p>还是一步一步来，我们把困难的任务分解来看。我们这里就做一个脚本，这个脚本是干什么的呢，就是读取一个文件夹里的Dockerfile，然后生成systemd可以解释的文件，然后执行他。至于这个Dockerfile怎么来的，先不考虑，我们就直接写一个Dockerfile，后来的时候应该是git push上来的。脚本代码应该是这样。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>\#!/bin/bash
</span><span class='line'>set -x
</span><span class='line'>
</span><span class='line'>WORKDIR=/etc/systemd/system
</span><span class='line'>APP="hello"
</span><span class='line'>sudo touch $WORKDIR/$APP.service
</span><span class='line'>SERVICE="$WORKDIR/$APP.service"
</span><span class='line'>sudo chmod o+w $SERVICE
</span><span class='line'>cat &gt; $SERVICE &lt;&lt;EOF
</span><span class='line'>[Unit]
</span><span class='line'>Description=$APP
</span><span class='line'>Requires=docker.service
</span><span class='line'>After=docker.service
</span><span class='line'>
</span><span class='line'>[Service]
</span><span class='line'>ExecStartPre=/usr/bin/docker build -t $APP /home/core/$APP
</span><span class='line'>ExecStartPre=/usr/bin/docker stop $APP
</span><span class='line'>ExecStartPre=/usr/bin/docker rm $APP
</span><span class='line'>ExecStart=/usr/bin/docker run -d -P --name $APP $APP
</span><span class='line'>
</span><span class='line'>[Install]
</span><span class='line'>WantedBy=multi-user.target
</span><span class='line'>EOF
</span><span class='line'>sudo systemctl enable /etc/systemd/system/$APP.service
</span><span class='line'>sudo systemctl daemon-reload
</span><span class='line'>sudo systemctl start $APP.service</span></code></pre></td></tr></table></div></figure>


<p>简单吧，读取/home/core/$APP路径下的Dockerfile，然后打包成一个image，然后删除可能存在的，然后运行。</p>

<p>后面我们将会讲解怎么把这两个简单的步骤组合起来，组合起来之后，就是一个简单的，具备paas平台过程的paas平台了，虽然还有很多需要修改，补充，完善的地方。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[设计自己的paas平台一]]></title>
    <link href="http://monkey-h.github.io/blog/my-paas-1/"/>
    <updated>2015-05-18T14:49:52+08:00</updated>
    <id>http://monkey-h.github.io/blog/my-paas-1</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>在理解了dokku，dokku-alt的基础上，我们设计自己的paas平台。我们的终极目标是在一个集群环境中设计一个paas平台，dokku只是单机环境下，为了我们的终极目标，我们最终选择的paas的底层平台是coreos集群环境。这几篇blog只是我们不断进行尝试的日志，并不是一个完整的教程，等我们最终搭建好了，可能会写一个完整的教程，但那都是后话。</p>

<!--more-->


<h3>coreos</h3>

<p>在<a href="coreos.com">coreos官网上</a>，coreos的副标题就是Linux for massive server deployments。coreos简单来说，就是为云环境而生的操作系统，真正的云操作系统。它具有很多操作系统没有的优点，它最初的设计源自于google的chromeos，对系统结构重新设计，剔除了任何不必要的软件和服务。适合集群环境，而不是传统的服务器操作系统。
没有提供包管理工具，通过容器化，向应用程序提供运算环境。应用程序之间共享系统内核和资源，但是彼此之间又互不可见。应用程序将不会再被直接安装到操作系统中，而是通过 Docker 运行在容器中。这种方式使得操作系统、应用程序及运行环境之间的耦合度大大降低。
采用双系统分区设计。ChromeOS最大的优点。两个分区分别被设置成主动模式和被动模式并在系统运行期间各司其职。主动分区负责系统运行，被动分区负责系统升级。一旦新版本的操作系统被发布，一个完整的系统文件将被下载至被动分区，并在系统下一次重启时从新版本分区启动，原来的被动分区将切换为主动分区，而之前的主动分区则被切换为被动分区，两个分区扮演的角色将相互对调。同时在系统运行期间系统分区被设置成只读状态，这样也确保了 CoreOS 的安全性。CoreOS 的升级过程在默认条件下将自动完成，并且通过 cgroup 对升级过程中使用到的网络和磁盘资源进行限制，将系统升级所带来的影响降至最低。
使用Systemd取代SysV作为系统和服务的管理工具。具备优秀的并行化处理能力，按需启动等特点。</p>

<p>既然说到coreos是最好的云操作系统，那么coreos和集群就联系的十分紧密了。coreos集群中最重要的是三个概念。docker，fleet，etcd。</p>

<p>docker技术我们这里就不在介绍了，docker技术也是我们研究的主题，如果docker技术都不懂，那么你根本不会看这篇blog。</p>

<p>其次是fleet。fleet 是一个通过 Systemd对CoreOS 集群中进行控制和管理的工具。每个 fleet agent 之间通过 etcd 服务来注册和同步数据。fleet 提供的功能非常丰富，包括查看集群中服务器的状态、启动或终止 Docker container、读取日志内容等，某个服务器脱离集群，其上面的所有服务都会转移到别的服务器上。包括部署高可用的服务等。fleet提供了很多好用的api接口，在后面我们会详细介绍。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/fleet_zps3dvxl6hl.png" alt="" /></p>

<p>最后是etcd。etcd技术是coreos的骨架。etcd 是一个分布式 key/value 存储服务，CoreOS 集群中的程序和服务可以通过 etcd 共享信息或做服务发现 。etcd 基于 raft 一致性算法：通过选举形式在服务器之中选举 Lead 来同步数据，并以此确保集群之内信息始终一致和可用
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/_zpscrifu3cf.png" alt="" /></p>

<h3>systemd</h3>

<p>在前面提到过，coreos是通过systemd来系统和服务的管理工具，同样的fleet也是通过systemd，看来，systemd的一些基本语法也是我们要了解的内容。</p>

<ul>
<li>sudo systemctl status xx.service 查看某个服务的状态。- sudo systemctl start xx.service- sudo systemctl stop xx.service- sudo systemctl kill xx.service- sudo systemctl restart xx.service- sudo systemctl daemon-reload 如果重启一个修改了service文件的服务，你必须reload service文件systemd由两个基本概念组成，unit和target。unit是一个配置文件，用来描述想要跑的进程的一些参数。target是一个grouping mechanism，用来允许systemd在同一时间起多个进程。systemd是coreos上启动的第一个进程。systemd进程读取不同的target，运行这些进程。每一个target一般是对unit文件的一个symlinks的集合，当运行systemctl enable foo.service 的时候，就会创建一个指向这个unit文件的symlinks，在multi-user.target.wants中。在coreos中，unit files一般位于/etc/systemd/system中，这个文件系统是可读写的。</li>
</ul>


<p>看个基本的例子。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[Unit]
</span><span class='line'>Description=MyApp
</span><span class='line'>After=docker.service
</span><span class='line'>Requires=docker.service
</span><span class='line'>
</span><span class='line'>[Service]
</span><span class='line'>TimeoutStartSec=0
</span><span class='line'>ExecStartPre=-/usr/bin/docker kill busybox1
</span><span class='line'>ExecStartPre=-/usr/bin/docker rm busybox1
</span><span class='line'>ExecStartPre=/usr/bin/docker pull busybox
</span><span class='line'>ExecStart=/usr/bin/docker run --name busybox1 busybox /bin/sh -c "while true; do echo Hello World; sleep 1; done"
</span><span class='line'>
</span><span class='line'>[Install]
</span><span class='line'>WantedBy=multi-user.target</span></code></pre></td></tr></table></div></figure>


<p>after和requires，这个基本定义了运行这个程序在哪个区间里，上面的例子就是说，只有在docker.service运行起来之后，才可以运行这个东西。execstart 在执行这个unit的时候，要干什么事情。这个进程的pid就是systemd监控的用来判断进程是否挂掉的进程。不要跑container用-d参数，这个参数会阻止container用这个pid的子进程来运行。这样systemd会认为这个进程已经退出了，那么这个unit也会被停止。wantedby指出这个unit是哪个targt的一部分。
- sudo systemctl enable /etc/systemd/system/hello.service会创建一个symlink。- sudo systemctl start hello.service- journalctl -f -u hello.service会读取hello.service的输出。- ExecStartPre 执行execstart之前要执行的命令。- execstart 这个unit的主要的执行命令。- execstartpost 当execstart执行结束，执行的命令。- execreload 当执行systemctl reload xx.service的时候，会执行的命令。- execstop 当unit被认为失败，或者执行systemctl stop xx.service的时候，执行的命令。- execstoppost 当execstop执行完成后，执行的操作。- RestartSec 当重启一个服务的时候，要睡眠多少秒，当预防失败的服务没100ms自己尝试restart的情况。- =-是忽视这条命令产生的错误。当我们删除一个不存在的container的时候，会报没有这个container错误，但是我们只是保险起见，所以这个并不能称为错误。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[图的三角形计数]]></title>
    <link href="http://monkey-h.github.io/blog/hadoop-4/"/>
    <updated>2015-05-08T09:05:02+08:00</updated>
    <id>http://monkey-h.github.io/blog/hadoop-4</id>
    <content type="html"><![CDATA[<h3>实验背景</h3>

<p>图的三角形计数问题是一个基本的图计算问题,是很多复杂网络分析(比如社 交网络分析)的基础。目前图的三角形计数问题已经成为了 Spark 系统中 GraphX 图计算库 所提供的一个算法级API。本次实验任务就是要在Hadoop系统上实现Twitter社交网络图的 三角形计数任务。
换句话说，这TM是mapreduce课程的作业啊，不做也得做啊！！！</p>

<!--more-->


<h3>实验要求</h3>

<p>一个社交网络可以看做是一张图(离散数学中的图)。社交网络中的人对应于图的顶点;社 交网络中的人际关系对应于图中的边。在本次实验任务中,我们只考虑一种关系——用户之 间的关注关系。假设“王五”在 Twitter/微博中关注了“李四”,则在社交网络图中,有一条对 应的从“王五”指向“李四”的有向边。图 1 中展示了一个简单的社交网络图,人之间的关注关 系通过图中的有向边标识了出来。
<img src="" alt="graph" />
本次的实验任务就是在给定的社交网络图中,统计图中所有三角形的数量。
在统计前,需要先进行有向边到无向边的转换,依据如下逻辑转换:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>IF ( A→B) OR (B→A) THEN A-B</span></code></pre></td></tr></table></div></figure>


<p>“A→B”表示从顶点 A 到顶点 B 有一条有向边。A-B 表示顶点 A 和顶点 B 之间有一条无向边。
一个示例见图 1,图 1 右侧的图就是左侧的图去除边方向后对应的无向图。 请在无向图上统计三角形的个数。在图 1 的例子中,一共有 3 个三角形。
+ 输入格式
输入数据仅一个文件。该文件由若干行组成,每一行由两个以空格分隔的整数组成:
A B
A,B 分别是两个顶点的 ID。这一行记录表示图中具有一条由 A 到 B 的有向边。整个图的结构由该文件唯一确定。
下面的框中是文件部分内容的示例:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>87982906 17975898
</span><span class='line'>17809581 35664799
</span><span class='line'>524620711 270231980
</span><span class='line'>247583674 230498574
</span><span class='line'>348281617 255810948
</span><span class='line'>159294262 230766095
</span><span class='line'>14927205 5380672
</span><span class='line'>......</span></code></pre></td></tr></table></div></figure>


<ul>
<li>输出格式
请在报告中报告如下内容:
1.实验设计说明,包括主要设计思路、算法设计、程序和各个类的设计说明
2.最终统计出的三角形个数
3.程序运行和实验结果说明和分析
4.性能、扩展性等方面存在的不足和可能的改进之处
5.源程序,执行程序
6.在集群上运行 MapReduce 作业的截屏、JobTracker 上记录的截屏</li>
</ul>


<h3>实验思路</h3>

<p>基本思路很简单，假如我们找到了 A->B 和 A->C 两个边，那么，我们只要去找有没有B->C这条边就可以了。
详细来说，我们使用了三个map reduce过程来实现这个东西。
- 第一个map reduce
map用来调换顺序，意思就是，我们把 A->B 和 B->A 都变成 A->B，这样有什么好处呢？之前实验要求里也说了， A->B 和 B->A 这两条有向边应该化成一条无向边，这第一个map reduce就是做这个事情的。这里，把 A->B 作为key。
reduce过程是去重，就是假如有多个A->B，记做一个边，当然如果实验要求不同，可以不同。
- 第二个mapreduce
map过程是把key A->B 拆开，把A作为key，把B作为value。这里是干什么呢？这里就是要寻找了，我们要找到需要的边，也就是上面举例中的B->C边存在不存在。
reduce过程，对value进行处理。比如key为A，那么，其value应该是所有和A有边的点。假如B,C，那么我们就要把B->C作为新的key，其value我们用&amp;来代替，意思就是这是我们要找的边。另一方面，我们不能把原来的边直接删掉，因为我们还是要从这里面找边，那么，还要有A->B,A->C这样的key，其value我们用#来表示，代表这是存在的边。
- 第三个mapreduce
map过程没有做上面事情，就是把第二部reduce的数据重新传到第三步的reduce。
reduce就是比对。我们找到每个key后面的value中，有没有#，如果有，就说明存在这个边，然后把除了#之外的&amp;的个数进行统计，和就是我们所需要的个数。最后通过一个cleanup函数，打印最后的统计结果即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import java.io.IOException;
</span><span class='line'>import java.util.ArrayList;
</span><span class='line'>import java.util.StringTokenizer;
</span><span class='line'>
</span><span class='line'>import org.apache.hadoop.fs.Path;
</span><span class='line'>import org.apache.hadoop.io.LongWritable;
</span><span class='line'>import org.apache.hadoop.io.Text;
</span><span class='line'>import org.apache.hadoop.mapreduce.Job;
</span><span class='line'>import org.apache.hadoop.mapreduce.Mapper;
</span><span class='line'>import org.apache.hadoop.mapreduce.Reducer;
</span><span class='line'>import org.apache.hadoop.util.GenericOptionsParser;
</span><span class='line'>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
</span><span class='line'>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
</span><span class='line'>import org.apache.hadoop.conf.Configuration;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>public class triangle {
</span><span class='line'>  
</span><span class='line'>  public static class sortMapper extends Mapper&lt;Object, Text, Text, Text&gt;{
</span><span class='line'>      private Text a = new Text();
</span><span class='line'>      private Text b = new Text();
</span><span class='line'>      
</span><span class='line'>      public void map(Object key,Text value,Context context)throws IOException,InterruptedException {
</span><span class='line'>
</span><span class='line'>          StringTokenizer itr=new StringTokenizer(value.toString());
</span><span class='line'>          long first = Integer.parseInt(itr.nextToken());
</span><span class='line'>          long second = Integer.parseInt(itr.nextToken());
</span><span class='line'>          if (first &lt;= second){
</span><span class='line'>              a.set(first+"#"+second);
</span><span class='line'>              b.set("#");
</span><span class='line'>          }
</span><span class='line'>          else{
</span><span class='line'>              a.set(second+"#"+first);
</span><span class='line'>              b.set("#");
</span><span class='line'>          }
</span><span class='line'>          context.write(a, b);
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public static class sortReducer extends Reducer&lt;Text, Text, Text, Text&gt;{
</span><span class='line'>      private Text b = new Text();    
</span><span class='line'>      public void reduce(Text key,Iterable&lt;Text&gt; values,Context context)throws IOException,InterruptedException {
</span><span class='line'>          //Text b = new Text();
</span><span class='line'>          b.set("#");
</span><span class='line'>          context.write(key, b);
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public static class findMap extends Mapper&lt;LongWritable, Text, Text, Text&gt;{
</span><span class='line'>      public void map(LongWritable key, Text value, Context context)throws IOException,InterruptedException {
</span><span class='line'>          StringTokenizer itr=new StringTokenizer(value.toString());
</span><span class='line'>          String[] tokens = itr.nextToken().toString().split("#");
</span><span class='line'>          //String[] tokens = value.toString().split("#");
</span><span class='line'>          String a = tokens[0];
</span><span class='line'>          String b = tokens[1];
</span><span class='line'>          //System.out.println(a+"    "+b);
</span><span class='line'>          Text left = new Text();
</span><span class='line'>          Text right = new Text();
</span><span class='line'>          left.set(a+"");
</span><span class='line'>          right.set(b+"");
</span><span class='line'>          context.write(left, right);
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public static class findReducer extends Reducer&lt;Text, Text, Text, Text&gt;{
</span><span class='line'>      
</span><span class='line'>       public void reduce(Text key,Iterable&lt;Text&gt; values,Context context)throws IOException,InterruptedException {
</span><span class='line'>           ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;();
</span><span class='line'>           Text left = new Text();
</span><span class='line'>           Text right = new Text();
</span><span class='line'>           right.set("#");
</span><span class='line'>           for(Text value : values){
</span><span class='line'>               array.add(value.toString());
</span><span class='line'>               left.set(key.toString()+"#"+value.toString());
</span><span class='line'>               context.write(left, right);
</span><span class='line'>           }
</span><span class='line'>           for(int i=0; i&lt;array.size(); i++){
</span><span class='line'>               for(int j=i+1; j&lt;array.size(); j++){
</span><span class='line'>                   Text a = new Text();
</span><span class='line'>                   Text b = new Text();
</span><span class='line'>                   if(Integer.parseInt(array.get(i)) &lt; Integer.parseInt(array.get(j))){
</span><span class='line'>                       a.set(array.get(i)+"#"+array.get(j));
</span><span class='line'>                       b.set("&");
</span><span class='line'>                   }
</span><span class='line'>                   else{
</span><span class='line'>                       a.set(array.get(j)+"#"+array.get(i));
</span><span class='line'>                       b.set("&");
</span><span class='line'>                   }
</span><span class='line'>                   context.write(a, b);
</span><span class='line'>               }
</span><span class='line'>           }
</span><span class='line'>       }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public static class combineMap extends Mapper&lt;LongWritable, Text, Text, Text&gt;{
</span><span class='line'>      private Text a = new Text();
</span><span class='line'>      private Text b = new Text();
</span><span class='line'>      public void map(LongWritable key,Text value,Context context)throws IOException,InterruptedException {
</span><span class='line'>          StringTokenizer itr=new StringTokenizer(value.toString());
</span><span class='line'>          a.set(itr.nextToken().toString());
</span><span class='line'>          b.set(itr.nextToken().toString());
</span><span class='line'>          context.write(a, b);
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public static class combineReducer extends Reducer&lt;Text, Text, Text, Text&gt;{
</span><span class='line'>      private static int result = 0;
</span><span class='line'>      //private Text a = new Text();
</span><span class='line'>      //private Text b = new Text();
</span><span class='line'>      
</span><span class='line'>      public void cleanup(Context context) throws IOException, InterruptedException{
</span><span class='line'>          context.write(new Text("Result: "), new Text(""+result));
</span><span class='line'>      }
</span><span class='line'>      
</span><span class='line'>      public void reduce(Text key,Iterable&lt;Text&gt; values,Context context)throws IOException,InterruptedException {
</span><span class='line'>          int count = 0;
</span><span class='line'>          int is_triangle = 0;
</span><span class='line'>          for(Text value : values){
</span><span class='line'>              if(value.toString().equalsIgnoreCase("#")){
</span><span class='line'>                  is_triangle = 1;
</span><span class='line'>              }else if(value.toString().equalsIgnoreCase("&")){
</span><span class='line'>                  count ++;
</span><span class='line'>              }else{
</span><span class='line'>                  //System.out.println("wrong input number");
</span><span class='line'>              }
</span><span class='line'>          }
</span><span class='line'>          if (is_triangle == 1){
</span><span class='line'>              result += count;
</span><span class='line'>          }
</span><span class='line'>          //b.set(result+"");
</span><span class='line'>          //context.write(key, new Text(count+""));
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public static void main(String[] args) throws Exception {
</span><span class='line'>        // TODO Auto-generated method stub
</span><span class='line'>        Configuration conf=new Configuration();
</span><span class='line'>        String[] otherArgs=new GenericOptionsParser(conf,args).getRemainingArgs();
</span><span class='line'>        if (otherArgs.length!=4) {
</span><span class='line'>            System.err.println("Usage:invertedindex&lt;in&gt; &lt;out1&gt; &lt;out2&gt; &lt;out3&gt;");
</span><span class='line'>            System.exit(2);
</span><span class='line'>        }
</span><span class='line'>        
</span><span class='line'>        Job job1 = new Job(conf, "job1");
</span><span class='line'>        job1.setJarByClass(triangle.class);
</span><span class='line'>        job1.setMapperClass(sortMapper.class);
</span><span class='line'>        job1.setMapOutputKeyClass(Text.class);
</span><span class='line'>        job1.setMapOutputValueClass(Text.class);
</span><span class='line'>        job1.setReducerClass(sortReducer.class);
</span><span class='line'>        job1.setOutputKeyClass(Text.class);
</span><span class='line'>        job1.setOutputValueClass(Text.class);
</span><span class='line'>
</span><span class='line'>        //job1.setInputFormatClass(TextInputFormat.class);
</span><span class='line'>        //job1.setOutputFormatClass(TextOutputFormat.class);
</span><span class='line'>        //job1.setMapOutputKeyClass(Text.class);
</span><span class='line'>        //job1.setMapOutputValueClass(Text.class);
</span><span class='line'>        
</span><span class='line'>        FileInputFormat.addInputPath(job1, new Path(otherArgs[0]));
</span><span class='line'>        FileOutputFormat.setOutputPath(job1, new Path(otherArgs[1]));
</span><span class='line'>        
</span><span class='line'>        job1.waitForCompletion(true);
</span><span class='line'>        
</span><span class='line'>
</span><span class='line'>        Job job2 = new Job(conf, "job2");
</span><span class='line'>        job2.setJarByClass(triangle.class);
</span><span class='line'>        job2.setMapperClass(findMap.class);
</span><span class='line'>        job2.setMapOutputKeyClass(Text.class);
</span><span class='line'>        job2.setMapOutputValueClass(Text.class);
</span><span class='line'>        job2.setReducerClass(findReducer.class);
</span><span class='line'>        job2.setOutputKeyClass(Text.class);
</span><span class='line'>        job2.setOutputValueClass(Text.class);
</span><span class='line'>        
</span><span class='line'>        //job2.setInputFormatClass(TextInputFormat.class);
</span><span class='line'>        //job2.setOutputFormatClass(TextOutputFormat.class);
</span><span class='line'>        //job2.setMapOutputKeyClass(Text.class);
</span><span class='line'>        //job2.setMapOutputValueClass(Text.class);
</span><span class='line'>        
</span><span class='line'>        FileInputFormat.addInputPath(job2, new Path(otherArgs[1]));
</span><span class='line'>        FileOutputFormat.setOutputPath(job2, new Path(otherArgs[2]));
</span><span class='line'>        
</span><span class='line'>        job2.waitForCompletion(job1.isComplete());
</span><span class='line'>     
</span><span class='line'>        Job job3 = new Job(conf, "job3");
</span><span class='line'>        job3.setJarByClass(triangle.class);
</span><span class='line'>        job3.setMapperClass(combineMap.class);
</span><span class='line'>        job3.setMapOutputKeyClass(Text.class);
</span><span class='line'>        job3.setMapOutputValueClass(Text.class);
</span><span class='line'>        job3.setReducerClass(combineReducer.class);
</span><span class='line'>        job3.setOutputKeyClass(Text.class);
</span><span class='line'>        job3.setOutputValueClass(Text.class);
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>        //job3.setInputFormatClass(TextInputFormat.class);
</span><span class='line'>        //job3.setOutputFormatClass(TextOutputFormat.class);
</span><span class='line'>        //job3.setMapOutputKeyClass(Text.class);
</span><span class='line'>        //job3.setMapOutputValueClass(Text.class);
</span><span class='line'>        
</span><span class='line'>        FileInputFormat.addInputPath(job3, new Path(otherArgs[2]));
</span><span class='line'>        FileOutputFormat.setOutputPath(job3, new Path(otherArgs[3]));
</span><span class='line'>        
</span><span class='line'>        job3.waitForCompletion(job2.isComplete());
</span><span class='line'>
</span><span class='line'>    }
</span><span class='line'>  
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vpn添加路由规则+octopress Push报错]]></title>
    <link href="http://monkey-h.github.io/blog/net-add/"/>
    <updated>2015-05-07T14:56:51+08:00</updated>
    <id>http://monkey-h.github.io/blog/net-add</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>关于vpn访问局域网内服务器和octopress deploy的时候报错，记录一下，年纪大了，老是忘记怎么做。</p>

<!--more-->


<ul>
<li><p>vpn添加路由规则
国内墙的厉害，没有vpn感觉就活不了，免费的vpn说不定就被封了，干脆买了一个，买的是一个叫做云梯VPN的VPN，用起来速度还可以，但是有一个不好的地方就是，他是转发所有流量的，就是说，他不会做一个判断，所有的流量都通过他的VPN转发出去。比如访问个百度的网址，也是先转到国外他的vpn服务器，然后从那里转发出来，查找国内的百度服务器。这样会相当慢，当然了，也不是很慢，况且我们翻墙主要是为了访问国外的资源，国内基本不怎么访问，也就无所谓了。但是，有一些情况比较特殊，因为我经常要访问我们局域网内的服务器，这就比较麻烦了，因为你转发到国外的服务器上之后，再转发给国内的时候，是找不到我们局域网内的服务器的，这就需要添加一个路由规则，让所有有关访问局域网内的ip的请求，不走vpn，而是走我们局域网内的路由器就可以了。
<code>sudo /sbin/route add -net 114.212 192.168.1.1</code>
114.212是我们局域网的ip地址段，后面的192.168.1.1是路由器的ip地址。</p></li>
<li><p>octopress rake gen_deploy报错
搭建好的octopress，刚开始gen_deploy的时候可以push，但是后来重启了机器，就不可以了，报错
<img src="http://i1066.photobucket.com/albums/u407/5681713/everything/octopress_zpsuen9rm2b.png" alt="" />
经查证，好像是本地的rsa key没有加入到本地的钥匙中，添加进去就可以了。
<code>ssh-add ~/.ssh/id_rsa</code></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在coreos系统下，同时添加flannel和私有仓库的参数]]></title>
    <link href="http://monkey-h.github.io/blog/flannel-registry/"/>
    <updated>2015-05-06T17:07:40+08:00</updated>
    <id>http://monkey-h.github.io/blog/flannel-registry</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>前面我们已经搭建好了一个coreos集群 <a href="http://monkey-h.github.io/blog/coreoschi-xian-an-zhuang/">看这里</a>，正如这篇blog里面说的一样，我们没有外网，所以我们自己搭建了一个私有仓库，方法可以去官网找，很简答的两行命令，这里就不再叙述。既然搭建了私服，我们就希望我们的这个集群使用这个集群。其次，我们搭建了一个集群，我们也希望屏蔽这是一个集群的概念，让用户用起来就像在使用一个主机的服务器一样，所以我们需要<a href="github.com/coreos/flannel">flanel</a>服务。这就涉及到给docker daemon添加多个参数，我们这里记录一下过程。同时，这也是如果在coreos集群中如何运行service的介绍。</p>

<!--more-->


<h4>添加私服参数</h4>

<p>我们的服务器是没有外网的，所以，从docker hub上下载一个镜像都是问题，所以我们搭建了一个私有的docker registry。关于docker registry的东西，其实也是很有意思的，如果以后有机会，我们还会写一篇文章来介绍docker registry。我们现在的方式是，自己建立一个私服，然后从可以连接外网的地方下载一些image，然后上传到私服，这样，就可以直接从我们的私服上下载了，而且速度相当快。因为是局域网内，而且没有经过国防网。
系统默认的docker.service在</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/usr/lib64/systemd/system/docker.service</span></code></pre></td></tr></table></div></figure>


<p>里面，但是这个路径下的文件是可读不可写的，所以我们要把他移动到一个可读可写的地方。不只是docker.service，只要是unit files都要在这个路径</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/etc/systemd/system</span></code></pre></td></tr></table></div></figure>


<p>所以，第一步，拷贝一份docker.service。并编辑。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo cp /usr/lib64/systemd/system/docker.service /etc/systemd/system/
</span><span class='line'>cd /etc/systemd/system
</span><span class='line'>sudo vim docker.service</span></code></pre></td></tr></table></div></figure>


<p>把其中的这句话</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ExecStart=/usr/lib/coreos/dockerd --daemon --host=fd:// $DOCKER_OPTS -- $DOCKER_OPT_BIP $DOCKER_OPT_MTU $DOCKER_OPT_IPMASQ</span></code></pre></td></tr></table></div></figure>


<p>改成</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ExecStart=/usr/lib/coreos/dockerd --daemon --host=fd:// $DOCKER_OPTS --insecure-registry docker.iwanna.xyz:5000 $DOCKER_OPT_BIP $DOCKER_OPT_MTU $DOCKER_OPT_IPMASQ</span></code></pre></td></tr></table></div></figure>


<p>加的那个参数，就是告诉本机，这个地址的私有仓库可以不走https协议，要不然在pull image的时候会报错。
<img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/insecure_zpsjexwxehm.png" alt="insecure" />
接下来，我们要让这个service生效，然后启动。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo systemctl stop docker.service
</span><span class='line'>sudo systemctl enable /etc/systemd/system/docker.service
</span><span class='line'>sudo systemctl daemon-reload
</span><span class='line'>sudo systemctl start docker.service</span></code></pre></td></tr></table></div></figure>


<p>接下来就可以pull私有仓库里可以编译flannel的image了。在docker hub里面，叫做google/golang是一个支持go语言的image，我在上传到私有仓库的时候，为了名字好记，重新命名了，实际上就是这个image。
<img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/pull_zpsihbxjfxl.png" alt="pull" /></p>

<h4>安装flannel</h4>

<p>现在我们已经从私服上下载下来了编译flannel的image，现在我们需要flannel的源码，由于我们这里不能使用外网，所以，还是通过tomcat的方式下载，如果可以使用外网，可以直接使用git clone来下载</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/coreos/flannel.git</span></code></pre></td></tr></table></div></figure>


<p>我们这里是从tomcat服务器上下载的。
<img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/wget_zpswmf12hii.png" alt="wget" />
接下来，解压，移动到/opt目录，为什么这么做，是为了防止以后误删。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar -zxf flannel.tar.gz
</span><span class='line'>sudo mkdir /opt
</span><span class='line'>sudo mv flannel/* /opt
</span><span class='line'>cd /opt</span></code></pre></td></tr></table></div></figure>


<p>好了，现在可以编译了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker run -v /opt:/opt/flannel -ti docker.iwanna.xyz:5000/hmonkey/flannel /bin/bash -c "cd /opt/flannel && ./build"</span></code></pre></td></tr></table></div></figure>


<p><img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/building_zps5vlcndnc.png" alt="building" />
接下来，我们就要创建flannel服务了。
进入到我们的unit files目录。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /etc/systemd/system
</span><span class='line'>sudo touch flannel.service
</span><span class='line'>sudo vim flannel.service</span></code></pre></td></tr></table></div></figure>


<p>在里面写入这样的代码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[Unit]
</span><span class='line'>Description=flannel
</span><span class='line'>Requires=etcd.service
</span><span class='line'>After=etcd.service
</span><span class='line'>
</span><span class='line'>[Service]
</span><span class='line'>ExecStartPre=-/usr/bin/etcdctl mk /coreos.com/network/config '{"Network":"10.0.0.0/16"}'
</span><span class='line'>ExecStart=/opt/bin/flanneld
</span><span class='line'>
</span><span class='line'>[Install]
</span><span class='line'>WantedBy=multi-user.target</span></code></pre></td></tr></table></div></figure>


<p>然后，启动这个服务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo systemctl enable flannel.service
</span><span class='line'>sudo systemctl start flannel.service</span></code></pre></td></tr></table></div></figure>


<p>可以查看状态，如果是这样，就说明成功了。
<img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/status_zpsk02mrnhs.png" alt="status" />
接下来，停掉docker.service，删除网桥docker0，让docker0使用flannel的网桥，然后修改docker.service，重启docker。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>source /run/flannel/subnet.env
</span><span class='line'>sudo systemctl stop docker.service
</span><span class='line'>sudo ifconfig docker0 ${FLANNEL_SUBNET}
</span><span class='line'>sudo vim docker.service
</span><span class='line'>sudo systemctl daemon-reload
</span><span class='line'>sudo systemctl start docker.service</span></code></pre></td></tr></table></div></figure>


<p>编辑docker.service的时候，使得最后，docker.service看起来是这个样子的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[Unit]
</span><span class='line'>Description=Docker Application Container Engine
</span><span class='line'>Documentation=http://docs.docker.com
</span><span class='line'>After=docker.socket early-docker.target network.target
</span><span class='line'>Requires=docker.socket early-docker.target
</span><span class='line'>
</span><span class='line'>[Service]
</span><span class='line'>Environment=TMPDIR=/var/tmp
</span><span class='line'>EnvironmentFile=-/run/flannel/subnet.env
</span><span class='line'>MountFlags=slave
</span><span class='line'>LimitNOFILE=1048576
</span><span class='line'>LimitNPROC=1048576
</span><span class='line'>ExecStart=/usr/lib/coreos/dockerd --insecure-registry docker.iwanna.xyz:5000 --bip=${FLANNEL_SUBNET} --mtu=${FLANNEL_MTU} --daemon --host=fd://
</span><span class='line'>
</span><span class='line'>[Install]
</span><span class='line'>WantedBy=multi-user.target</span></code></pre></td></tr></table></div></figure>


<p>好了，大功告成，验证一下。
我们在coreos3上随便跑一个container，可以看到，他的ip是我们之前用flannel获得的。
<img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/try_zpsdxnqxstq.png" alt="try" />
然后我们在coreos1上，ping这个ip，可以看到，完全可以ping通。
<img src="http://i1066.photobucket.com/albums/u407/5681713/flannel%20regitstry/ping_zpsfvnfwq69.png" alt="ping" />
同样的，简单学习一下systemd的语法，就可以让我们开启不同的service，如果这些service中有涉及到有可能修改docker daemon的参数的，就可以通过上面这个例子进行修改。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[创建不需要输入密码就可以登录的docker Image]]></title>
    <link href="http://monkey-h.github.io/blog/ssh-image/"/>
    <updated>2015-05-06T16:55:39+08:00</updated>
    <id>http://monkey-h.github.io/blog/ssh-image</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>ssh进入某一个机器的时候，要么提供那台机器的密码，要么采用别的安全协议，比如说rsa协议，我们就是通过rsa协议实现了不输入密码就可以直接登录别的主机。这样做主要是为了，我们在利用mpi进行计算的时候，不能通过输入密码的方式进行访问，所以，有这个需求。</p>

<!--more-->


<p>而rsa的工作原理是什么样子的呢？简单说来，如果a想ssh到b上去，那么a就要把自己的rsa.pub发送给b，然后，b如果接受a以后可以无密码访问我，就把这个pub key加入到authorized_keys里面去，这样以后，在a想ssh到b的时候，a会把这个信息进行加密，通过a自身的private key，而a的这个加密信息只有a的pub key才能解开，这样，b在接收到这个信息的时候，因为b拥有a的pub key，所以就可以解开，同样地，b也就知道，这真是a发来的信息，因为别的人不知道a的private key，这样b就可以直接允许a ssh进来了。
在docker环境中，我们比较方便的地方，是可以直接制作一个镜像。我们的想法是，用一个基础镜像构建一个container，然后在这个container里面生成rsa密钥，然后，把自己的pub key直接拷到authorized_keys里面去，然后把这个container做成一个镜像，这样的话，只要从这个镜像起来的container，都可以互相无密码访问。
首先，要用docker启用一个container</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -ti ubuntu /bin/bash</span></code></pre></td></tr></table></div></figure>


<p>既然要使用ssh，那么我们肯定要安装ssh。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo apt-get install openssh-server</span></code></pre></td></tr></table></div></figure>


<p>然后，生成密钥，并且赋值给authorized_keys</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sshkey-gen -t rsa</span></code></pre></td></tr></table></div></figure>


<p>一直按回车，不要停。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cp /root/.ssh/id_dsa.pub /root/.ssh/authorized_keys</span></code></pre></td></tr></table></div></figure>


<p>修改一些配置信息，修改/etc/ssh/ssh_configure文件里面的StrictHostKeyChecking ask为 no，这个配置信息是在ssh主机的时候，询问加入fingerprint的那个东西。
然后退出container，使用docker ps -l查看刚刚退出的container的id，然后用这个container commit一个镜像。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker commit container_id image_name</span></code></pre></td></tr></table></div></figure>


<p>那么最终生成的那个image_name，就是我们设计出来的一个image，从这个image启动不同的container之后，在开启了ssh服务的情况下，是可以相互不输入密码ssh进去的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用mtt作为mpi的benchmark 测试docker Container计算集群性能]]></title>
    <link href="http://monkey-h.github.io/blog/mpi-benchmark/"/>
    <updated>2015-05-06T16:31:43+08:00</updated>
    <id>http://monkey-h.github.io/blog/mpi-benchmark</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>docker技术已经十分普遍，利用docker来创建多个虚拟机，实现分布式运算也是一种十分便利的方式，但是docker创建的虚拟机和常规的虚拟机，或者和分布式的集群到底有多少性能的差距，docker能不能通过创建多个container的方式实现常规的分布式运算，我们这里使用openmpi的一个benchmark，mtt来做一个验证。</p>

<!--more-->


<h3>为什么这么做</h3>

<p>早些时候老板让做了一个open mpi的image，并在单机环境下，成功使用docker搭建了一个openmpi的集群，可以跑一些hello world的例子。后来，在ubuntu环境下，使用openvswitch搭建了一个多host的集群，在coreos环境下，使用etcd键值对服务和搭建了一个集群，并分别通过tunnel的方式，和flannel的方式，修改docker -d的参数，使得，在不同的host主机上，可以运行在同一个子网内的container，并且相互之间可以通信。参见这篇<a href="http://monkey-h.github.io/blog/shi-yong-vagrantda-jian-coreosji-qun-an-zhuang-flannelfu-wu-bing-shi-yong-mpi-benchmarkce-shi/">blog</a>。
前几天老板说，你成功搭建了，跑hello world的例子也成功了，但是你这个性能怎么样，多host情况下，你是通过tunnel桥，或者flannel实现的，那么你这样的性能和单host肯定是不一样的，性能差多少呢？你要找个benchmark来检验一下，所以，我就找了个openmpi的mtt来测试一下，这里做个记录。
我们先来说说mtt是个什么东西，mtt是一个检验mpi环境的，不只是openmpi，包括别的版本的mpi也是可以的。第一，mtt会检验你是否正确安装了mpi，甚至mtt可以帮助你安装mpi。第二，mtt会检验你写的代码是否可以通过安装的mpi成功编译。第三，mtt会检验你写的程序是否可以正确在集群环境中运行，并返回集群中云心的结果，包括是否成功啊，花费的时间等。第三个特点，也正是我们需要的功能。
首先要明确的一个观点就是，肯定要搭建一个nfs，或者说，也可以使用别的方法，比如开个docker container作为data container，然后通过这种方式同步也可以，如果单节点当然可以，但是在多节点的时候就不可以了，因为data container不能跨节点共享数据。我们为什么要在不同节点之间共享数据呢？想象一下，我们在运行mtt的时候，他会运行我们的测试程序，那么这个测试程序，理论上只有在我们运行mtt的host才会有，那么怎么让那些slave节点也去运行这个程序呢？mtt并不帮助我们把测试程序传到slave节点上去，需要我们自己拷贝，或者通过别的简单方式，别如我们刚刚说的通过data container的方式，或者nfs。由于我们需要在不同的host节点上创建slave，所以我们这里肯定要搭建nfs服务。否则在运行mtt的时候，会报cannot find execute path file之类的错误。</p>

<h3>搭建nfs</h3>

<p>首先，在主host上安装nfs服务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo apt-get install nfs-kernel-server
</span><span class='line'>sudo apt-get install nfs-common</span></code></pre></td></tr></table></div></figure>


<p>注意一定要安装nfs-common服务，有的文章指出不需要安装，因为在安装nfs-kernel-server的时候，会自动安装nfs-common和nfs-portmap，我尝试后发现，portmap是自动安装了，但是，并没有安装nfs-common，会报</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mount wrong nfs type, bad option, bad superblock on XXX</span></code></pre></td></tr></table></div></figure>


<p>的错误。
然后，配置nfs共享目录。假如我们需要共享的目录是/home/monkey/nfs文件夹下的所有文档，那么我们就需要配置/etc/exports文件，在最后一行，加上这么一句。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>"/home/monkey/nfs" *(rw,sync,no_subtree_check)</span></code></pre></td></tr></table></div></figure>


<p>至于这句话什么意思，前面的路径肯定就是我们要共享的nfs文件，后面的的意思是，所有ip段的机器都可以共享这个路径，如果你要指定某个机器，可以直接把替换成那台机器的ip，比如114.212.87.52，或者你要指定某个子网段的机器，可以这样写，114.212.0.0/24，这种东西查查nfs配置就知道了，我们这里不作为重点。后面的rw是读写权限，ro是read only，sync是同步等，自己查查文档。
配置好后，重启服务，</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo /etc/init.d/portmap resatrt
</span><span class='line'>sudo /etc/init.d/nfs-kernel-server restart</span></code></pre></td></tr></table></div></figure>


<p>就可以了。我们可以输入showmount -e来进行查看。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/mount_zpsoynx36iw.png" alt="mount" />
ok，这样nfs就配置完成了。</p>

<h3>docker配置多节点mpi cluster</h3>

<p>这一步就比较简单了，因为我们之前已经做好了open mpi的image，在docker hub上也有，如果有同学不想自己做的话，可以自己去下载，名字是hmonkey/openmpi14.04:v3。启动的时候，一定要注意给container超级权限。否则会出现挂载nfs共享文件夹的时候报错的问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cannot mount on ip readonly</span></code></pre></td></tr></table></div></figure>


<p>类似于这样的错误。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -ti --name master --privileged=true hmonkey/openmpi14.04:v3 /bin/bash
</span><span class='line'>sudo docker run -ti --name slave1 --privileged=true hmonkey/openmpi14.04:v3 /bin/bash
</span><span class='line'>sudo docker run -ti --name slave2 --privileged=true hmonkey/openmpi14.04:v3 /bin/bash</span></code></pre></td></tr></table></div></figure>


<p>这样就起来了三个节点，其中我们把其中的一个座位master，另外的两个座位slave。起来之后，要做两件事，第一，我忘记在image里面自动启动ssh服务，所以，起来之后，要首先把ssh服务启动起来，分别运行sudo service ssh start其次，要在master里面把slave的ip加到host列表里面去，这样才可以方便的访问。在master上vim /etc/hosts，把slave1和slave2的地址加上去。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/host_zpslj6kzrht.png" alt="host" />
这样，就配置好集群环境了。由于我们这里已经设置好ssh进去的时候不需要输入密码，这一步就可以省略了。关于如何配置不需要密码就可以直接ssh进去，请查看我别的<a href="http://monkey-h.github.io/blog/ssh-image/">blog</a>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /
</span><span class='line'>sudo mkdir nfs
</span><span class='line'>sudo mount ip:/home/monkey/nfs /nfs</span></code></pre></td></tr></table></div></figure>


<p>这样就可以了，这样就把宿主机的nfs文件夹，和当前container的nfs文件夹同步起来了，在三个container上都要这么做。注意这里的ip就是我们宿主机的ip，也就是我们搭建的nfs服务的那个节点的ip。</p>

<h3>下载并运行mtt</h3>

<p>在master容器内，</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /
</span><span class='line'>git clone https://github.com/open-mpi/mtt
</span><span class='line'>cd mtt/sample
</span><span class='line'>cat developer.ini trivial.ini | ../client/mtt - hostlist=slave1,slave2 alreadyinstalled_dir=/usr --scratch=/nfs</span></code></pre></td></tr></table></div></figure>


<p>最后一句命令比较难以理解。其中，developer.ini里面是检测你是否正确安装了mpi，trivial.ini是跑测试的程序的。../client/mtt是mtt的运行脚本，hostlist是要检验的集群中的机器，alreadyinstall_dir是你把mpi安装在哪里了，scratch是最重要的，是要写配置的nfs共享目录在container里的位置。
当运行结束时，如果出现这样的画面，就说明，mpi环境运行通过，并且，有数据显示，可以和常规的集群，或者虚拟机进行比较。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/1_zpsguiwjprd.png" alt="1" />
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/2_zps3ucpl1xn.png" alt="2" />
最后提醒一句，mtt的代码已经迁移到github上了，如果你使用</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>svn checkout https://svn.open-mpi.org/svn/mtt/branches/ompi-core-testers</span></code></pre></td></tr></table></div></figure>


<p>这样的命令去下载mtt，那么他会一直让你输入username 和 passwd。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用vagrant搭建coreos集群安装flannel服务并使用mpi测试]]></title>
    <link href="http://monkey-h.github.io/blog/shi-yong-vagrantda-jian-coreosji-qun-an-zhuang-flannelfu-wu-bing-shi-yong-mpi-benchmarkce-shi/"/>
    <updated>2015-05-06T15:20:00+08:00</updated>
    <id>http://monkey-h.github.io/blog/shi-yong-vagrantda-jian-coreosji-qun-an-zhuang-flannelfu-wu-bing-shi-yong-mpi-benchmarkce-shi</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>容器技术已经成为了当前技术的潮流，学习容器技术已经刻不容缓。除了原始的warden容器，docker容器之外，coreos也在发展自己的容器技术，rocket，就连之前不看好容器技术的microsoft也开始创建自己的容器技术，nano server。我们这里尝试搭建coreos集群，并安装了flannel服务，用来实现mpi程序的测试。</p>

<!--more-->


<h4>需要的软件支持</h4>

<p>我们采用的是使用vagrant + virtualbox的方式来搭建coreos集群，所以，这两个软件的正确安装是必不可少的。</p>

<h4>coreos集群安装</h4>

<p>在之前的blog <a href="http://monkey-h.github.io/blog/coreoschi-xian-an-zhuang/">coreos离线安装</a> 里面，我们已经在服务器上安装了coreos集群，但是并不是所有的同学都有这么多资源，可以有那么多的服务器可以使用。通过搭建虚拟机的方式又很慢，所以，我们这里采用vagrant + virtualbox的方式来搭建集群。
使用vagrant搭建coreos集群官网，官网上有coreos集群通过vagrant搭建的具体步骤，基本没有什么坑，我们这里简单说明一下。
首先，在宿主机目录下，下载coreos-vagrant的git代码，并进入代码目录。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/coreos/coreos-vagrant.git
</span><span class='line'>cd coreos-vagrant</span></code></pre></td></tr></table></div></figure>


<p>接着，我们就可以修改其中的某些参数，来搭建我们的集群了。
首先，把示例代码拷贝一下，我们这里直接重命名了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mv user-data.sample user-data
</span><span class='line'>mv config.ruby.sample config.ruby</span></code></pre></td></tr></table></div></figure>


<p>接着，修改两个文件的参数。打开config.ruby，把里面的</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#$num_instance=1</span></code></pre></td></tr></table></div></figure>


<p>改成</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$num_instance=3</span></code></pre></td></tr></table></div></figure>


<p>因为我们搭建的集群如果只有一台机器，是没有意义的。
还有把</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#$update_channel='alpha'</span></code></pre></td></tr></table></div></figure>


<p>改成</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$update_channel='stable'</span></code></pre></td></tr></table></div></figure>


<p>我们还是使用比较稳定的版本较好，免得出现乱起八糟的问题。
打开user-data，把里面的</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#discovery: https://discovery.etcd.io/&lt;token&gt;</span></code></pre></td></tr></table></div></figure>


<p>改成</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>discovery: https://discovery.etcd.io/&lt;token&gt;</span></code></pre></td></tr></table></div></figure>


<p>至于是怎么来的，你可以访问这个网址，这个网址可以自动生成一个唯一的，用来达到建立集群的目的。至于这个东西有什么用，可以去查etcd的文档，简单来说，就是每个启动的机器都会去找这个token，找到了，就连接到这个集群中，从而实现集群的建立。
打开Vagrantfile，修改</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>config.vm.box_version "&gt;= 308.0.1"</span></code></pre></td></tr></table></div></figure>


<p>为</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#config.vm.box_version "&gt;= 308.0.1"</span></code></pre></td></tr></table></div></figure>


<p>就是把他删掉，因为后面可能会报这个错误，这个又不是必须的，我们就直接删掉。
好了，该修改的都修改了，这个时候，就可以大胆的启动了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vagrant up</span></code></pre></td></tr></table></div></figure>


<h4>flannel搭建</h4>

<p>vagrant搭建完成后，我们就可以进入搭建好的coreos主机了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vagrant ssh core-01 -- -A</span></code></pre></td></tr></table></div></figure>


<p>分别进入三个主机，三个主机的名字分别为core-01，core-02，core-03。现在假如我们进入了core-01。我们可以在里面看到集群中所有的机器。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>fleetctl list-machines</span></code></pre></td></tr></table></div></figure>


<p><img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/list_zpshwqj6n0d.png" alt="list" />
可以看到，集群中一共有三台机器，ip也都是知道的。接着，让我们来安装flannel服务。在每台机器里，都这么做。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /
</span><span class='line'>git clone https://github.com/coreos/flannel.git
</span><span class='line'>mv /flannel /opt
</span><span class='line'>cd opt
</span><span class='line'>sudo docker run -v /opt:/opt/flannel -ti google/golang /bin/bash -c "cd /opt/flannel && ./build"</span></code></pre></td></tr></table></div></figure>


<p>然后，采用etcd的键值对服务，设置全局子网域。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>etcdctl rm /coreos.com/network --recursive
</span><span class='line'>etcdctl mk /coreos.com/network/config '{"Network":"10.0.0.0/16"}'</span></code></pre></td></tr></table></div></figure>


<p>然后启动flannel服务。注意，我们在启动集群的时候，eth0网卡是通过nat方式和host主机连在一起的，但是，eth1是和别的host主机在同一个局域网的网卡，所以我们在启动flannel服务的时候，要制定eth1网卡。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo /opt/bin/flanneld -iface=eth1 &</span></code></pre></td></tr></table></div></figure>


<p>flannel启动。在core-02和core-03上运行相同的过程。但是我们的docker并没有使用指定的子网，所以，我们还要重新运行docker，让他使用我们指定的子网。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>source /run/flannel/subnet.env
</span><span class='line'>sudo rm /var/run/docker.pid
</span><span class='line'>sudo ifconfig docker0 ${FLANNEL_SUBNET}
</span><span class='line'>sudo docker -d --bip=${FLANNEL_SUBNET} --mtu=${FLANNEL_MTU}</span></code></pre></td></tr></table></div></figure>


<p>大功告成，检验一下，<code>ifconfig</code>
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/flannel_zpspjmjfrk6.png" alt="" />
这里可以看到，我们的flannel0已经建成。同时
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/docker_zpsqy85ijfh.png" alt="" />
docker0也已经是我们指定的ip了。</p>

<h4>mpi应用测试</h4>

<p>我在dockerhub上上传了一个关于mpi的镜像，我们这里可以下载下来运行一下。
在core-01上，运行</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -ti --name master hmonkey/openmpi14.04:v3 /bin/bash</span></code></pre></td></tr></table></div></figure>


<p>在core-02上运行</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -ti --name slave1 hmonkey/openmpi14.04:v3 /bin/bash</span></code></pre></td></tr></table></div></figure>


<p>在core-03上运行</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -ti --name slave2 hmonkey/openmpi14.04:v3 /bin/bash</span></code></pre></td></tr></table></div></figure>


<p>然后在core-01上，</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /mpi`
</span><span class='line'>touch hostfile
</span><span class='line'>vi hostfile //在里面添加slave1和slave2的ip地址。
</span><span class='line'>mpirun -n 3 -hostfile hostfile mpi_hello</span></code></pre></td></tr></table></div></figure>


<p>大功告成，结果如下
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos/mpi_zps1vidqse2.png" alt="" />
要注意的是，我的mpi镜像忘记默认启动ssh服务了。如果运行mpi应用的时候包connect refused，把ssh服务打开就可以了</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coreos集群离线安装]]></title>
    <link href="http://monkey-h.github.io/blog/coreoschi-xian-an-zhuang/"/>
    <updated>2015-05-06T09:54:34+08:00</updated>
    <id>http://monkey-h.github.io/blog/coreoschi-xian-an-zhuang</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>最近要搭建一个coreos集群，但是实验环境中没有外网，这样就不能使用官网的安装方法，整合了一些大牛的安装经验，加上我自己的安装实践，这里做个记录，希望大家可以少踩一些坑。</p>

<!--more-->


<h4>刻录安装盘</h4>

<p>官网给的coreos的镜像是一个iso文件，我们需要把他刻成安装盘，中文的大白菜，比较好的UltroISO都可以，我一般都是用后者，不会用大白菜，但是据很多装系统的人描述，大白菜好像挺简单的。
我是在服务器上安装的，他自带一个iDRAC虚拟控制台，可以直接从iso安装，就省略了刻盘的过程。</p>

<h4>启动服务器</h4>

<p>如果用的iso安装盘，直接从U盘启动，就可以进入到一个系统，如果从iDRAC虚拟控制台，从虚拟CD DVD ISO启动，就可以进入到一个预安装系统，这个系统是用来帮助你安装系统的，这个时候，系统并没有安装到你的服务器上。</p>

<h4>配置临时ip地址</h4>

<p>由于我们没有外网，所以我们需要在本地局域网开一个tomcat服务器，从这个tomcat服务器里面下载我们需要的东西，那么为了可以获得这个tomcat服务器的东西，我们就需要给这台机器临时分配一个内网ip。
首先，我们先看看我们都有几个网卡。使用<code>ifconfig | less</code>命令。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/ifconfig_zps44mqiukv.png" alt="ifconfig" />
从上图中我们可以看到，我这台服务器上有两个网卡，我们就使用eno1来分配ip。
进入到/etc/systemd/network目录，分配内网ip。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /etc/systemd/network
</span><span class='line'>sudo vi static.network</span></code></pre></td></tr></table></div></figure>


<p>编辑static.network如下所示。</p>

<p><img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/staticnetwork_zps6zii1usf.png" alt="staticnetwork" /></p>

<p>注意，Name后面的eno1应该是上一步ifconfig出来的网卡的名称，Address后面的ip地址应该是你要分配的你的子网内的ip地址，网关也是对应的网关，DNS也是你自己的DNS解析器，当然，如果没有，可以不写。
接下来，使得网络生效。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo systemctl restart systemd-networkd</span></code></pre></td></tr></table></div></figure>


<p>可以通过ping你的tomcat服务器来看看是否设置成功。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/ping_zpshqq6duxh.png" alt="tomcat" /></p>

<h4>配置tomcat服务器和上传安装脚本，配置文件</h4>

<p>配置tomcat服务器的教材有很多，我们这里就不再描述了，可以随便google一个，然后配置好。我们这里要讲的就是coreos的安装脚本和配置文件。
<a href="https://raw.githubusercontent.com/coreos/init/master/bin/coreos-install">https://raw.githubusercontent.com/coreos/init/master/bin/coreos-install</a>这个是官网给的安装脚本，首先我们要把他下载下来，然后，把他放在刚刚配置的tomcat路径下，tomcat/webapps/ROOT路径下。然后修改其中的一些内容。
<img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/coreos-install_zpshx5fw1ft.png" alt="install" />
这里的ip要配置成你本机的ip，并且是可以被服务器连接到的ip。理解起来也很简单，就是把去网上要下载的东西，都从本机下载。那么很明显，我们也要把他要下载的东西，也预先下载下来，放在ROOT目录下。有两个东西，一个是镜像，也就是要安装的东西，一个是签名，是用来检测下载的镜像有没有破损之类的。（我们这里下载的是607版本的，现在应该有更新了）
镜像地址：<a href="http://stable.release.core-os.net/amd64-usr/607.0.0/coreos_production_image.bin.bz2">http://stable.release.core-os.net/amd64-usr/607.0.0/coreos_production_image.bin.bz2</a>
签名地址：<a href="http://stable.release.core-os.net/amd64-usr/607.0.0/coreos_production_image.bin.bz2.sig">http://stable.release.core-os.net/amd64-usr/607.0.0/coreos_production_image.bin.bz2.sig</a>
除了这个东西，还有一个配置文件，叫做cloud-config.yaml。这个文件是安装coreos系统必不可少的文件。我们这里默认要装的东西不多，所以cloud-config.yaml文件就简单了很多，如下。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#cloud-config
</span><span class='line'>  
</span><span class='line'>hostname: coreos1
</span><span class='line'>  
</span><span class='line'>coreos:    
</span><span class='line'>  etcd:      
</span><span class='line'>    peers: 114.212.189.136:7001
</span><span class='line'>    addr: 114.212.189.136:4001  
</span><span class='line'>    peer-addr: 114.212.189.136:7001  
</span><span class='line'>  units:  
</span><span class='line'>    - name: etcd.service  
</span><span class='line'>      command: start  
</span><span class='line'>    - name: fleet.service  
</span><span class='line'>      command: start  
</span><span class='line'>    - name: static.network  
</span><span class='line'>      content: |  
</span><span class='line'>        [Match]  
</span><span class='line'>        Name=eno1
</span><span class='line'>  
</span><span class='line'>        [Network]  
</span><span class='line'>        Address=114.212.189.136/24  
</span><span class='line'>        Gateway=114.212.189.1
</span><span class='line'>      DNS=202.119.32.6
</span><span class='line'>users:    
</span><span class='line'>  - name: core  
</span><span class='line'>    ssh-authorized-keys:   
</span><span class='line'>      - ssh-rsa #你的rsa key
</span><span class='line'>  - groups:  
</span><span class='line'>      - sudo  
</span><span class='line'>      - docker </span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#cloud-config
</span><span class='line'>  
</span><span class='line'>hostname: coreos2
</span><span class='line'>  
</span><span class='line'>coreos:    
</span><span class='line'>  etcd:      
</span><span class='line'>    peers: 114.212.189.136:7001
</span><span class='line'>    addr: 114.212.189.143:4001  
</span><span class='line'>    peer-addr: 114.212.189.143:7001  
</span><span class='line'>  units:  
</span><span class='line'>    - name: etcd.service  
</span><span class='line'>      command: start  
</span><span class='line'>    - name: fleet.service  
</span><span class='line'>      command: start  
</span><span class='line'>    - name: static.network  
</span><span class='line'>      content: |  
</span><span class='line'>        [Match]  
</span><span class='line'>        Name=eno1
</span><span class='line'>  
</span><span class='line'>        [Network]  
</span><span class='line'>        Address=114.212.189.143/24  
</span><span class='line'>        Gateway=114.212.189.1
</span><span class='line'>        DNS=202.119.32.6
</span><span class='line'>users:    
</span><span class='line'>  - name: core  
</span><span class='line'>    ssh-authorized-keys:   
</span><span class='line'>      - ssh-rsa #你的rsa key
</span><span class='line'>  - groups:  
</span><span class='line'>      - sudo  
</span><span class='line'>      - docker </span></code></pre></td></tr></table></div></figure>


<p>这是两个服务器的cloud-config.yaml文件的比较，对比一下就很明显了。要修改的地方如下。
+ hostname 看你心情怎么命名，但是每个最好不一样。
+ peers 这个是etcd服务建立集群用来发现新机器的，除了第一台服务器安装的时候，是自己的ip，其余的都要使用集群中已经存在的某一个主机的ip。
+ addr 本机的ip和默认用来配对的4001端口
+ peer-addr 本机的ip和默认的用来配对的7001端口
+ Address 本机ip，前面的addr就是根据这个设置的，两个要一致。
+ Gateway 网关。你的局域网的网关
+ DNS 域名服务器，如果没有，可以不设置
+ ssh-rsa rsa密钥，启动服务器后，不能使用密码登陆，一般都是使用rsa密钥对来登陆，所以，这里要配置。至于rsa怎么产生，你可以在一个ubuntu系统上ssh-keygen命令参数，然后把~/.ssh/id_rsa.pub拷贝过来就是了。然后，你就可以从这个ubuntu系统登陆服务器，如果想从别的系统登陆，只要把那个系统的id_rsa.pub拷到服务器的authorized_keys里面就可以了。
+ 要注意，推荐你直接复制我拷上去的命令，因为cloud-config.yaml文件很特殊，他的语法很奇怪，比如DNS前面不是tab，而是8个空格等，如果这些你用的不对，就很容易出错。</p>

<h4>下载安装脚本和配置文件，并安装</h4>

<p>准备就绪，可以安装了。在服务器上下载需要的安装脚本和配置文件。并给安装脚本赋予权限。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd ~
</span><span class='line'>wget 172.28.11.65:8080/coreos-install
</span><span class='line'>chmod +x coreos-install
</span><span class='line'>wget 172.28.11.65:8080/cloud-config143.yaml</span></code></pre></td></tr></table></div></figure>


<p>注意这里的cloud-config143.yaml就是我们上一步提到的，不同的机器对应的不同的cloud-config文件。
安装</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo ./coreos-install -d /dev/sda -C stable -c cloud-config143.yaml</span></code></pre></td></tr></table></div></figure>


<p><img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/success_zps7auwgjzn.png" alt="sucess" />
出现这个界面就说明成功了，然后重启就可以了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo reboot</span></code></pre></td></tr></table></div></figure>


<p>重启好了之后，你可以从你刚刚那个ubuntu系统ssh进去了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh core@114.212.189.143</span></code></pre></td></tr></table></div></figure>


<p><img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/login_zpssxrdse5c.png" alt="login" />
同样的，使用基本相同的步骤，不同的cloud-config.yaml文件，配置其余的机器，配置完成后，在其中的一台机器上，查看集群中有哪些机器。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>fleetctl list-machines</span></code></pre></td></tr></table></div></figure>


<p><img src="http://i1066.photobucket.com/albums/u407/5681713/coreos-install/listmachines_zpskqtipnkp.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dokku源码解读四]]></title>
    <link href="http://monkey-h.github.io/blog/dokkuyuan-ma-jie-du-si/"/>
    <updated>2015-05-05T19:50:07+08:00</updated>
    <id>http://monkey-h.github.io/blog/dokkuyuan-ma-jie-du-si</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>dokku，号称只用了100行左右代码就实现的简单paas平台，号称是你能见到的最小的paas平台，确实，很NB。整个dokku的实现大部分采用了bash脚本命令，只有少数的go语言文件，我们接下来就通过几篇blog，来看看，dokku到底是怎么实现的这个pass平台。</p>

<!--more-->


<h3>dokku服务器端操作</h3>

<p>在dokku搭建的dokku平台上，有如下一些基本命令。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/help_zpsawheqycp.png" alt="" />
在前面我们已经介绍过了，如果在dokku源码文件里找不到对应的case命令，就会去plugins/**/command里面去找。对这些命令而言，在这些目录下都是可以找到的，而且代码的可读性很强，我们这里就不再一个一个介绍，找几个比较有意思的，常用的命令介绍一下。</p>

<ul>
<li>apps:create <app>
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/create_zpsuwx8dj6q.png" alt="" />
第一个判断语句是在用户没有指定创造的应用的名字的时候的提示语句。
第二个判断语句是在已经存在指定名字的应用的时候的提示语句。
创造的过程就是在$DOKKU_ROOT路径下建造了一个$APP的文件夹，就创建完成了，是不是和我们想象中的不一样？也就是说，dokku的apps:create并不是创建了一个应用，而只是创建了一个文件夹而已，如果你想创建应用容器，还是需要用docker run来做。</li>
<li>apps:destroy <app>
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/destroy_zpsqccw8iun.png" alt="" />
和create不同的是，删除就是真正的删除了，除了我最后圈出来的那两个停止容器，和删除容器的操作之外，前面还有很多准备工作，比如，用箭头指出来的，和<a href="deis.com">deis</a>很像的一个防止用户误删的判断操作，和支持强制删除等操作。值得注意的是，在最后，dokku还删除了对应的image，用来由于部署的应用过多，从而空间不够的情况，当然了，这种情况可能会导致上传之前已经部署过的一个应用，需要重新制作镜像的情况，可能会花费的时间多一些，但是，瑕不掩瑜。</li>
<li>backup:export [file]
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/backup_zps9ctf2nbl.png" alt="" />
这里我们要注意到一件事情，就是这里实际是调用了<code>pluginhook backup-export 1 $BACKUP_DIR</code>，要注意的是，我们从整个源码的目录结构里面可以看到，有很多backup-export文件，pluginhook的一个机制是，当有很多相同名字的插件的时候，他会把所有的插件都执行一遍，这样才是dokku的需求，可以把很多需要备份的东西，在不同的地方写上，而不会产生冲突，这也是让dokku发展pluginhook的一个很大的需求点，要不然，dokku很有可能会直接采用hook机制实现这些东西。</li>
<li>ls
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/ls_zpszlg1xjln.png" alt="" />
可以看到，dokku查找所有应用容器的方式相当简单，因为每次创建一个容器，他都会在$DOKKU_ROOT目录下创建一个对应的文件夹，所以，只要读取这个文件夹就可以了，没有用到docker的那一套，简单多了。</li>
<li>run
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/run_zpsi0vbhyap.png" alt="" />
这个run我们可以看到，应该是在create之后做的事情，这个run的前提是$DOKKU_ROOT目录下，已经存在了需要run的应用的目录，包括里面应有的文件。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dokku源码解读三]]></title>
    <link href="http://monkey-h.github.io/blog/dokkuyuan-ma-jie-du-san/"/>
    <updated>2015-05-04T18:48:02+08:00</updated>
    <id>http://monkey-h.github.io/blog/dokkuyuan-ma-jie-du-san</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>dokku，号称只用了100行左右代码就实现的简单paas平台，号称是你能见到的最小的paas平台，确实，很NB。整个dokku的实现大部分采用了bash脚本命令，只有少数的go语言文件，我们接下来就通过几篇blog，来看看，dokku到底是怎么实现的这个pass平台。</p>

<!--more-->


<h3>dokku文件源码解读</h3>

<p>上一节说到执行dokku receive $APP，找到文件中对应的代码
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/dokku-receive_zpsg2szjbzf.png" alt="dokku-receive.png" />
其实，在执行这段代码之前，还有一些命令要执行，这些命令是主要是一些准备工作，包括环境变量的设置，插件的安装激活，还有原始命令的执行。
在receive的case里面，主要做了四件事情，包括cleanup，build，release和deploy。
+ cleanup主要有两行命令组成，第一行，是删除paas平台中，状态为推出的container，可以看到，他是直接通过docker的命令执行的。关于docker，如果没有接触过的话，可以看看<a href="docker.com" title="docker 官网">这里</a>。第二行命令，是删除一些没有打标签的image，这些image一般是在生成新的image的过程中产生的临时文件。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/dokku-cleanup_zpsqkmhu8qc.png" alt="dokku-cleanup.png" />
+ build是用来产生要部署的程序的image的。build和release的case在plugins/00_dokku-standard/command里面可以找到。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/dokku-build_zpso6pqkn0n.png" alt="dokku-build.png" />
dokku支持两种部署应用的方式，一种是heroku的标准格式，另外一种是dockerfile的格式，我们可以从代码的两个case中看到。我们先看简单的，dockerfile更加简单一些。
dockerfile的case中，第一步，查看dockerfile中有没有写EXPOSE，如果有，取出想要暴露的端口，并通过dokku config:set-norestart命令，设置成对应程序的环境变量。dokku config:set-norestart命令我们之后再解释。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pluginhook pre-build-dockerfile "$APP"
</span><span class='line'>pluginhook post-build-dockerfile "$APP"</span></code></pre></td></tr></table></div></figure>


<p>这两个插件在后来的更新中都去除了，所以，这两句不会执行。
还有一句<code>docker build -t .</code>这个是docker的标准的从当前路径，查找Dockerfile，生成image的语法，这样就生成了一个用来部署应用的image。
除了dockerfile的case，还有一个buildstep的case。在我们安装dokku这个paas平台的时候，就在makefile里面做了一个特殊的image
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/buildstep_zpsdvkmpj8u.png" alt="buildstep.png" />
这个image是安装了heroku标准解释程序的image。而我们后来上传的按照heroku标准写的应用程序，就是通过这个东西来执行的。在dokku文件里，</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export DOKKU_IMAGE=${DOKKU_IMAGE:="progrium/buildstep"}</span></code></pre></td></tr></table></div></figure>


<p>也就是在这个case里面的$DOKKU_IMAGE，实际上就是之前做的那个image，前面的几行是利用这个可以解释标准heroku的image跑一个container，然后在里面解压需要部署的应用，也就是相当于把应用拷贝进去，之后，commit成一个镜像。中间的几行，查看是否有一些container在启动的过程中的特殊的参数，加上去，执行build，heroku就是通过这个东西来部署应用。部署好了之后，commit成一个镜像。最后一部分，是一些build之后的处理，但是在后来的版本这些东西已经取消了。
+ release部分。和build类似，release也是有两个部分，dockerfile和buildstep。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/dokku-release_zpss2dcay6b.png" alt="dokku-release.png" />
dockerfile的部分没有做任何事情，buildstep部分，是把dokku paas平台的一些参数设置导入到了container之中，具体是什么参数，我们可以看到
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/env_zpsjkxrnn0s.png" alt="" />
主要是等待时间等。这里面的<code>if [[ -f "$DOKKU_ROOT/ENV" ]]</code>是去判断是否存在这个文件，关于if和文件的组合判断，可以去看我的另外一篇blog里面介绍的东西。<a href="http://monkey-h.github.io/blog/bash-trick/" title="bash trick">点击这里</a>
+ deploy部分
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/dokku-deploy_zpsbofppa5l.png" alt="deploy" />
在deploy的开始阶段，首先执行了<code>pluginhook pre-build $APP</code>这段代码调用了plugin的一个插件，pre-build，这个插件可以在plugins/build-env/pre-build中找到
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/pre-build_zpsktyjirfr.png" alt="pre-build" />
这个插件的作用也是十分明显的，第一，把原来build阶段的环境变量设置成应用的变量（大部分还是一些等待时间等变量），第二，把所有的build阶段的参数，都累加起来，再启动一个容器，把这些变量添加到这个容器中，然后把这个容器commit成一个image，让接下来的启动都从这个image中启动。
接下来，就需要启动这个app了。首先判断是否已经起了一个这样的应用，如果已经启动了，那么我们就需要知道已经启动的这个容器的id是多少。由于我们在每次部署应用的时候，都会把他的id设置到$DOKKU_ROOOT/$APP/CONTAINER里面去，所以，直接读出来这个东西就ok了。为什么要知道这个id，是由于我们后面要把旧的container杀死，所以必须知道。接下来，DOCKER_ARGS参数已经在后来的版本中取消了，不用看了。要注意，我们执行了这么一句话。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>BIND_EXTERNAL=$(pluginhook bind-external-ip $APP)</span></code></pre></td></tr></table></div></figure>


<p>这个插件在plugins/nginx-vhost/bind-external-ip里面
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/bind-ip_zpsejjdrghn.png" alt="" />
这个函数是通过查看应用的repository，看看有没有设置绑定外网ip的参数，如果有，就返回true，否则返回false.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>is_image_buildstep_based "$IMAGE"</span></code></pre></td></tr></table></div></figure>


<p>是用来判断我们之前通过build和release阶段的时候，出来的image是通过dockerfile出来的，还是通过标准heroku来解析的。如果是前者，那么，Dockerfile中应该制定了程序入口，端口之类的东西，如果没有端口指定也不影响，如果是后者，在执行docker run的时候，只要执行/start web实际上就是启动了应用容器，这是由heroku来做的事情。
接下来通过我们之前做的是否制定了ip来判断，如果没有指定ip，那么，这个应用容器的ip就是跑起来的时候的docker分配的ip地址，通过</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker inspect --format '' $id</span></code></pre></td></tr></table></div></figure>


<p>来查询。而port当Dockerfile中没有指定的时候，就默认是5000，如果制定了，就是指定的端口。启动应用容器也是很简单，加上-e PORT的参数，docker的其他参数，image我们也制定好了，$START_CMD也是，如果是buildstep的就是/start web，如果是dockerfile的，那么就是dockerfile中定义的entrypoint。这样就启动了应用容器。如果指定了ip，那么也是差不多的，只不过，容器的ip不再是docker分配的地址，启动的时候，参数照样加，不过端口指定为容器的5000端口，至于host主机暴露的端口是多少，我们可以通过<code>docker port $id container_ip</code>获得。而ip就是本机了。
接着，做一个对部署的应用的检查，如果成功了，就可以使用新的容器了。
使用新的容器，就要把原来的容器的id啊，ip啊，port啊之类的参数都修改了，那么再次有用户访问的时候，就是新的容器了。
新的容器部署好了之后，还要把旧的容器给删除，<code>docker kill $oldid</code>就可以了。
+ url
最后的时候，还做了一件事，就是，部署好了，怎么访问呢？或者说怎么告诉用户怎么访问呢？这就用到了<code>dokku url "$APP"</code>
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/url_zps7uw8gcug.png" alt="" />
从这里可以看到，这个函数就是打印出了IP地址和端口号，也就是docker部署container的标准访问方式。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dokku源码解读二]]></title>
    <link href="http://monkey-h.github.io/blog/dokkuyuan-ma-jie-du-%5B%3F%5D/"/>
    <updated>2015-05-04T17:03:52+08:00</updated>
    <id>http://monkey-h.github.io/blog/dokkuyuan-ma-jie-du-[?]</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>dokku，号称只用了100行左右代码就实现的简单paas平台，号称是你能见到的最小的paas平台，确实，很NB。整个dokku的实现大部分采用了bash脚本命令，只有少数的go语言文件，我们接下来就通过几篇blog，来看看，dokku到底是怎么实现的这个pass平台。</p>

<!--more-->


<h3>dokku进入点</h3>

<p>我们都知道git和ssh密不可分，从前面的知识我们也知道，当git push的时候，会首先执行ssh <a href="&#x6d;&#97;&#x69;&#x6c;&#116;&#x6f;&#x3a;&#x67;&#105;&#116;&#x40;&#x67;&#105;&#116;&#46;&#x63;&#x6f;&#x6d;">&#103;&#105;&#116;&#x40;&#103;&#105;&#x74;&#46;&#99;&#x6f;&#109;</a> git-receive-pack mygit.git这个操作，我们也说过了，这个会是dokku的入口。
我们停止服务器端的ssh服务，重新使用debug模式开启。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo service ssh stop
</span><span class='line'>sudo /usr/sbin/sshd -d</span></code></pre></td></tr></table></div></figure>


<p>然后在客户端重新部署一个服务，可以看到这样的提示。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/sshd_zpspxi2f2st.png" alt="sshd" />
我们去看看，/home/dokku/.sshcommand做了什么。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat /home/dokku/.sshcommand</span></code></pre></td></tr></table></div></figure>


<p>输出
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/catsshcommand_zpsmucywnao.png" alt="catsshcommand" />
这也就说明，不管你原来的命令是什么（$SSH_ORIGINAL_COMMAND），dokku都在这个命令前面增加了一个/usr/local/bin/dokku，也就是修改了客户端ssh进去的进入点，从而实现了进入pass平台部署任务的功能。
那么这个.sshcommand是怎么来的呢？我们去查看我们的安装文档，我这里是使用的vagrant安装的，我们可以去查看Vagrantfile文件。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/vagrantfile_zpsm3ofhsjy.png" alt="vagrantfile" />
在这里面，我们可以看到，这里只要是用的makefile安装的，我们接着查看Makefile。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/sshcommand_zps4po9ghg4.png" alt="sshcommand" />
这里可以看到，下载了一个脚本文件，然后执行了</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sshcommand create dokku /usr/local/bin/dokku</span></code></pre></td></tr></table></div></figure>


<p>命令，我们可以从makefile中找到SSHCOMMAND_URL的网址</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SSHCOMMAND_URL ?= https://raw.github.com/progrium/sshcommand/master/sshcommand</span></code></pre></td></tr></table></div></figure>


<p>进入到这个网址，我们可以看到
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/sshcommandcreate_zps1gqu4vme.png" alt="sshcommand" />
也就是说，在安装dokku paas平台，这个地步的时候，加入了了这个进入点。</p>

<h3>dokku push流程（git插件文件夹解读）</h3>

<p>我们现在来浏览一遍，dokku完整的push一个应用都做了什么。
首先，我们先把dokku源码的目录整理一下。
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/structure_zpshzuy9dmb.png" alt="structure" />
其次，我们已经说过了，dokku修改了进入点，当执行git-receive-pack的时候，并不是直接直接执行，而是修改成了/usr/local/bin/dokku git-receive-pack，那么这样一来，就是调用dokku的命令了。我们从目录结构里面找到dokku文件，在这里面的case里面，并没有找到git-receive-pack这个case，但是，我们找到了一个通配的东西
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/dokku-git_zps32ecyn2r.png" alt="dokku-git*" />
从这里面可以看到，如果找不到对应的case，就去$PLUGIN_PATH/*/command里面去找，直到找到对应的东西。$PLUGIN_PATH路径下的东西就是我们源码中plugins路径下面的东西，我们可以直接在源码里面找。plugins里面的东西的命名还是很科学的，基本每个文件下的都是相关的hook。我们可以在plugins/git/command里面找到相关的东西</p>

<p><img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/git-git_zpsjy8lits8.png" alt="git-git*" />
这里当遇到是git-receive-pack命令的时候，就先初始化一个空的git仓库，然后写了一个脚本，给这个脚本附上可执行权限，并执行。脚本里执行的是</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dokku git-hook $APP</span></code></pre></td></tr></table></div></figure>


<p>同样的，我们在相同的文件里面，找到git-hook
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/git-hook_zpspnl5souw.png" alt="git-hook" />
这里主要是判断用户push是否push到了master分支上，如果没有，提示如何push，如果正确push了，就执行,说明这是一个新push的应用。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pluginhook receive-app $APP $newrev</span></code></pre></td></tr></table></div></figure>


<p>既然是pluginhook方式的调用，我们肯定要在$PLUGIN_PATH里面查找这个文件了，这个文件也在git文件夹里面
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/receive-app_zpshkokzbhu.png" alt="receive-app" />
可以看到，这里执行了</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dokku git-build $APP $REV</span></code></pre></td></tr></table></div></figure>


<p><img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/git-build_zpsjk6xccvx.png" alt="git-build" />
这里有两个case，git-build判断是否这个app正在部署，或者被加锁了，否则就加锁，开始部署。git-build-locked就要开始真正的部署了。同样的文件夹找到git_build_app_repo()，
<img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/git-build-app_zpsvyxylgsi.png" alt="git-build-app" />
首先，检查一下app name，看看是否为空，或者是否不存在这个app目录，verify_app_name()这个函数在plugins/common/functions这里面，然后建造一个用来run这个应用的临时目录，并把应用拷贝到这个临时目录，最后，通过查看应用中有没有Dockerfile来判断，接下来执行的命令。但是不管有没有dockerfile，都会执行dokku receive命令。
终于，我们在dokku源码文件中，找到了receive的case分支。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dokku源码解读一]]></title>
    <link href="http://monkey-h.github.io/blog/dokkudao-di-gan-liao-shi-yao/"/>
    <updated>2015-05-01T09:05:19+08:00</updated>
    <id>http://monkey-h.github.io/blog/dokkudao-di-gan-liao-shi-yao</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>dokku，号称只用了100行左右代码就实现的简单paas平台，号称是你能见到的最小的paas平台，确实，很NB。整个dokku的实现大部分采用了bash脚本命令，只有少数的go语言文件，我们接下来就通过几篇blog，来看看，dokku到底是怎么实现的这个pass平台。</p>

<!--more-->


<h3>背景知识</h3>

<ul>
<li><p>git
  git是一个分布式版本控制软件，那么什么是版本控制呢？简单来说，版本控制就是一种记录一个或若干文件内容变换，以便将来查阅特定版本修订情况的系统，分为集中式版本控制和分布式版本控制。除了Git，还有像Mercurial，Bazaar，Darcs等。Git的客户端并只是提取最新版本的文件快照，而是把代码仓库完整地镜像下来，这样的话，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复，因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。
  Git可以简单理解成客户端/服务器（C/S）模型，客户端就是客户使用的，用来上传repository和下载repository，修改repository的地方，那么服务器是什么东西呢？不要害怕，其实服务器端更简单。通俗点讲，服务器就是一个文件存储系统，push的时候，就是把本地的repository上传到这个服务器的某一个目录，clone的时候，就是把那个目录的文件下载下来而已，只不过在部署服务器，上传的时候，可能会做一些初始化而已，这都不是重点。
  关于Git我们这里就不再更多的介绍，大家可以在<a href="git-scm.com/book/zn" title="git中文介绍">这里</a>看到最详细的介绍，下面我们说一点dokku使用的Git的一个小技巧。
  当我们在客户端git push的时候，在服务器端，到底做了什么？当push的时候，首先，会通过ssh的密钥机制来检验你是否有资格push，如果有资格，那么在服务器端，接收到你push的命令的时候，会首先执行
  <code>
  ssh git@git-repositry.com git-receive-pack 'my-app.git'
 </code>
  这个命令。是不是很神奇，知道了这个，我们就知道了dokku平台的入口在哪里，那么，接下来，所有的事情都好解释了。</p></li>
<li><p>pluginhook
  pluginhook并不是被大家普遍使用的一个项目，这是dokku的原作者自己提出，并且用在自己的项目，比如dokku中的一个子项目。那么，这个项目是不是就很难理解？其实不是，如果换个名字，大家估计就会很熟悉，hook。Git本身就有hook机制，其作用主要是，当某些重要时间发生时，Git以调用自定义的脚本。在Git中，有两组挂钩，客户端和服务器端的。客户端主要用于客户端的操作，像你在commit的时候，可能同时希望可以提交和合并等，但是对一个paas平台而言，关注的更多是服务器端的hook脚本。服务器端的hook Git脚本，通常被一些开发者用来做自动部署，也就是说，当用户通过客户端git push操作后，服务器端在收到这个commit之前，之后，都可以自动调用.git/hooks目录下的一些脚本文件，并执行。非常适合自动部署，在用户push之后，不需要再到服务器端，执行部署工作。hook脚本的作用就是这样，那么pluginhook又做了什么事情呢？pluginhook的项目代码很少，只有不到200行的go语言的代码。是一个比hook本身更好的plugin system。相对于hook脚本，pluginhook更关注plugin，什么意思呢？就是说，他把所有的hook脚本都集中在一个plugins的目录里，当然，这个目录也是特定的目录，这样，操作系统才知道怎么去找plugin的目录。同一个hook脚本，可以有多个plugin，调用的时候，这些plugin都会去执行。简单来说呢，pluginhook就是对hook进行了一层封装，把原本调用hook脚本的地方，用pluginhook来调用，如hook脚本调用
  <code>
  hooks/post-commit $REV $USER
 </code>
  可以用pluginhook这样调用
  <code>
  pluginhook post-commit $REV $USER
 </code>
  pluginhook命令就是简单的把plugin目录下的所有路径都找一遍，这个路径是通过环境变量$PLUGIN_PATH来定义的，只要找到和命令相同的文件的名字，就把这个命令之后的参数都传给这个文件，让他执行。那么，用pluginhook和hook有什么区别呢？可以这么说，不用pluginhook，只用hook也是可以完全实现这些功能的。使用hook，一是为了方便，二是，每个我们需要处理的点，只能有一个hook脚本实现，这是dokku所不希望的事情，所以，才有了pluginhook的出现。
  关于pluginhook的实现的代码阅读，我们之后再补充。</p></li>
<li><p>ssh
  ssh也是dokku修改的一个点，也是关于如何把git push后，在服务器端触发git-receive-pack的时候，默认调用dokku处理的部分。当我们在终端，将项目push到dokku平台的时候，假如我们打开dokku平台ssh服务的-x模式，也就是debug模式，我们可以看到这么一句话。
  <img src="http://i1066.photobucket.com/albums/u407/5681713/octopress/sshd_zpspxi2f2st.png" alt="email" />
  可以看到，dokku做了一件事情，他把所有的命令，都通过/home/dokku/.sshcommand这个文件一遍，这样就实现了进入dokku平台的自主控制界面，后面，他像干什么就干什么了。那么他是怎么实现这个功能的呢？这就和ssh的机制有关了。
  ssh有一个叫做ssh forced command的机制。如果在服务器的.ssh/authorized_keys前面，添加一个command=&ldquo;&#8221;，那么ssh进来，不管执行什么命令，都是从这个地方进入。也就是说，假如我们这里写的是command=&#8221;echo hello&#8221;，那么，不管ssh的时候，执行了什么命令，都只会执行echo hello这个东西。注意$SSH_ORIGINAL_COMMAND这个命令是ssh进来的时候的原始命令。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bash 脚本语言学习收获]]></title>
    <link href="http://monkey-h.github.io/blog/bash-trick/"/>
    <updated>2015-04-29T19:12:01+08:00</updated>
    <id>http://monkey-h.github.io/blog/bash-trick</id>
    <content type="html"><![CDATA[<h3>写在前面</h3>

<p>之前一直以为脚本语言就是简单的一种编程语言，不需要过多的了解，只要知道一点皮毛，哪里用到哪里学习一下就可以了，但是，读了一段牛人写的bash脚本程序之后，看不懂，查了bash的基本语法，才知道，原来bash是这么牛掰的一门语言，准备花两天系统学习一下，今天看了一部分，记录一下自己觉得很有意思，之前不知道的东西。</p>

<!--more-->


<h3>学习笔记</h3>

<ol>
<li><p>bash执行脚本的时候，会fork出来一个subshell来执行。那么，在脚本里设置的一些变量，就只有那个subshell知道，别的都不知道，也就是说，会被直接遗忘掉。使用export也是一样的效果。同时，注意在赋值的时候，是hello=”1”，不要忘记了没有空格和要有双引号。</p></li>
<li><p>如果不想开一个新的subshell来执行脚本，可以使用source script.sh这样来执行，这样就会在这个shell进程里来执行脚本，这样就可以保留里面设置的变量，包括export的环境变量，但是，结束了这个终端，也是不会被保留的。source在bash里面，可以使用.来替代。. script.sh也能达到这样的效果。</p></li>
<li><p>脚本文件第一行的#！尽量不要省略，这一行代表了这个脚本通过什么脚本命令程序来执行，如果你希望通过bash来执行脚本，但是没有指定，系统默认的又是别的脚本程序，那么就很有可能会出错。</p></li>
<li><p>当脚本出错的时候，如果想调试，没必要到脚本文件里面，通过注释代码的方式来调试，可以使用-x命令，bash -x script.sh来调试，这样，会让脚本文件一步一步执行，并在执行每一行命令前，打印出执行的哪一句命令，同时可以在脚本文件里加上，set -x …. set +x，来在常规执行的时候，就进入debug模式的一段代码。</p></li>
<li><p>按照惯例，bash的变量一般都是大写字母的组合，bash的变量有两种，一种是global variable，可以通过env或者printenv来查看，这些变量是在所有的shell里面都共用的。还有一种叫做local variable，这种变量只有在当前shell才有用。变量不能以数字开头。再次强调，在赋值的时候，等号周围是不能有空格的。可以通过unset 变量的方式，来把原来赋给变量的值清除掉。</p></li>
<li><p>一些特殊的值</p>

<ul>
<li>$0 当前脚本的名字，或者终端的名字。</li>
<li>$n 其中，n可以是1，2，3等，代表传入脚本的参数的值，不是从0开始的。</li>
<li>$# 参数的总个数。</li>
<li>$$ bash的进程id</li>
<li>$! 最近执行的后台命令的进程ID</li>
</ul>
</li>
<li><p>单引号可以让一些变量保持字面含义，比如echo ‘$date’ 输出是$date，而不是日期，同时，注意单引号不能嵌套单引号。但是双引号就不同了，双引号内，可以嵌套双引号，同时，如果加了$，是可以引用变量的，比如echo “$date” 输出的就不是$date，而是现在的日期。除了$，还有’’，echo “‘date’”和加$一样呢的效果。</p></li>
<li><p>一些小的trick
 echo sp{el,il,al}l
 spell spill spall
 (大括号的优先级是最高的)
 ~常被用来解析成$HOME，如~/path等。有两个特殊的应用~+代表的是当前路径，~-代表的是上一次进入的路径。
 允许通过:=的方式赋值，比如echo ${FRANKY:=FRIDY} 输出 FRIDY
 假如使用了”$(COMMAND)”的方式，那么，其中的所有字符都会被当做命令，而不会特殊处理。
 如果想在命令里进行计算，有两种方式，$((2+2)) 或者$[2+2]这两种方式，echo这两个结果，都是4</p></li>
<li><p>这是一个神奇的命令，是替代，别名的意思，我们可以使用这个东西来简化命令。
 比如，cd ../是回到上一层目录，假如我们使用alias ..=’cd ../’，然后，以后只要打..就可以回到上一层，如果想去除这个简写，只要unalias ..就可以了。当然这个修改只是暂时的，如果想一直这么做，就需要修改./bashrc或者/etc/profile文件。</p></li>
<li><p>正则表达式</p>

<ul>
<li>. 配对单个字符</li>
<li>? 代表最多一个字符，要么匹配，要么没有。</li>
<li>* 任意多个字符，可以没有一个</li>
<li>+ 和*一样，但是至少要匹配一次。</li>
<li>{N} 精确匹配N次</li>
<li>{N,} 精确匹配至少N次</li>
<li>{N,M} 精确匹配N到M次即可。</li>
<li>\ 下一个字符标记为一个特殊字符</li>
<li>| 匹配两边中的一个。</li>
<li>[xyz] 匹配其中的任意一个字符</li>
<li>[^ xyz] 匹配不是这三个中的字符，任意个</li>
<li>^xx 匹配某一行xx开头的文字</li>
<li>xx$ 匹配某一行xx结尾的文字</li>
<li>&lt;xx 某一个单词是xx开头的</li>
<li>>xx 某一个单词是xx结尾的。</li>
<li>- 表示范围。常用的就这么多，还有很多，百度一下，google一下就出来了。</li>
</ul>
</li>
<li><p>sed 是stream editor的简称，是一个编译器，具有很NB的功能。要注意的是，sed并没有修改文档的内容，只是打印修改后的文档。
基本命令：</p>

<ul>
<li>a 在当前行下添加文本</li>
<li>c 当前行变换内容</li>
<li>d 删除文本</li>
<li>i 当前行前增加文本</li>
<li>p 打印文本</li>
<li>r 读一个文件</li>
<li>s 查找并替代文本</li>
<li>w 写到一个文件
举个例子， <code>sed ‘/erors/p’ example</code>的意思就是，在example文件里面，查找有erors的行，并打印出来，假如我们这么写，那么就会把所有的文本都打印出来，只不过，有erors的行，打印两遍，所以我们要这么写<code>sed -n ‘erors/p’ example</code>
假如要删除，<code>sed ’/erors/d’ example</code>，这样就会删除有erors的行。
假如我们知道要删除的行是第几行，可以通过这么删除，<code>sed ‘2,4d’ example</code> 这样就删除了2-4行。同时可以使用正则表达式等。
<code>sed -n ‘/a text/,/This/p’ example</code>，这句话的意思就是，从example中匹配，打印从第一个包含a text的行，到保护This的那一行截止。
<code>sed ‘s/erors/errors’ example</code> 查找并替代。但是这样只会替代第一行，如果要替代所有的，需要<code>sed ‘s/erors/errors/g’ example</code>
如果多次查找和替换，需要使用-e参数。
<code>sed -e ‘s/erors/erros/g’ -e ‘s/last/final/g’ example</code>
同时，可以将结果输出到某一个文件。使用>即可。</li>
</ul>
</li>
<li><p>if语句。
注意在if [  ]的方括号里面，括号的左右是要有空格的。
常用的用来判断文件的一些参数。</p>

<ul>
<li>-a 存在即为真</li>
<li>-d 是否是个目录</li>
<li>-e 是否存在</li>
<li>-f 是否存在，且是一个常规文件</li>
<li>-r 是否可读</li>
<li>-s 是否大小不为0</li>
<li>-w 是否可写</li>
<li>-z 如果后面的string长度为0</li>
<li>-n 如果后面的string长度不为0</li>
<li>-x 是否有执行权限
<code>if [ -f /home/monkey/hello ]</code>
<code>then</code>
<code>echo “file exist”</code>
<code>fi</code>
可以写成
<code>if [ -f /home/monkey/hello ]; then</code>
<code>echo “file exist</code>
<code>fi</code>
可以写成
<code>[ -f /home/monkey/hello ] &amp;&amp; (echo “file exist”)</code>
如果是当条件不满足做什么东西的时候，就是用||。
但是，一般很少用这种代码，大部分都会采用test这个内置命令，来检验一些问题。比如
上面的判断语句可以改为
<code>test -f /home/monkey/hello &amp;&amp; echo file exist</code></li>
</ul>
</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello World]]></title>
    <link href="http://monkey-h.github.io/blog/hello-world/"/>
    <updated>2015-04-28T17:46:50+08:00</updated>
    <id>http://monkey-h.github.io/blog/hello-world</id>
    <content type="html"><![CDATA[<p><code>hello! world</code></p>
]]></content>
  </entry>
  
</feed>
